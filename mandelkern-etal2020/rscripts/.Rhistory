theme(panel.grid.minor = element_blank()) +
theme(strip.background = element_rect(fill="white")) +
theme(strip.text = element_text(color = "white"))
ggsave("../graphs/naturalness-by-context-and-expression.pdf",height=3,width=9)
m = lmer(Answer ~ context + (1+context|subject) + (1+context|item), data=subset(results[results$trigger == "sure",]))
summary(m)
summary(m)
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
theme_set(theme_bw())
# load libraries
library(plyr)
library(lme4)
library(lmerTest)
library(ggplot2)
library(tidyverse)
library(broom)
library(emmeans)
library(ordinal)
library(brms)
# load helpers
source('../../results/helpers.R')
# load data
results <- read.csv("../data/resultsExp1.csv")
# first plots
results$Condition <- (as.factor(as.character(results$Condition)))
levels(results$Condition) <- c("NoPsFirst", "NoPsSecond", "PsFirst", "PsSecond", "EISimplePs", "SSimplePs")
results <- as_tibble(results)
results <- results %>%
mutate(Condition = fct_relevel(Condition,
c("PsFirst", "PsSecond", "NoPsFirst", "NoPsSecond", "EISimplePs", "SSimplePs")))
resultsPlot <- results %>%
group_by(Condition) %>%
dplyr::summarize(n = n(), MeanValue = mean(Value), sd = sd(Value))%>%
mutate( se=sd/sqrt(n))  %>%
mutate( ci=se * qt((1-0.05)/2 + .5, n-1))
colours <- c("#727272", "#f1595f", "#79c36a", "#599ad3", "#f9a65a" , "#9e66ab")
ggplot(resultsPlot, aes(x = Condition, y = MeanValue, fill=Condition))+
geom_bar(stat = "identity") +
ylim("1", "2", "3", "4", "5", "6", "7")+
geom_errorbar(aes(ymin=MeanValue-se, ymax=MeanValue+se), width=.1) +
scale_fill_manual(values=colours)+
theme(axis.text.x = element_text(angle = 45)) +
theme_classic() +
labs(title = "Mean rating per condition",
y = "Mean rating",
x = "Condition")
# filter to data of interest (SSimplePs = support simple ps, EISimplePS = explicit ignorance simple ps)
d = results %>%
filter(Condition == "SSimplePS" | Condition == "EISimplePs") %>%
droplevels()
table(d$Condition)
# filter to data of interest (SSimplePs = support simple ps, EISimplePS = explicit ignorance simple ps)
d = results %>%
filter(Condition == "SSimplePs" | Condition == "EISimplePs") %>%
droplevels()
table(d$Condition)
# target data: explicit ignorance context
t = d %>%
filter(Condition == "EISimplePs")
nrow(t)
table(t$trigger)
view(t)
table(t$Trigger)
table(t$Value) #0-6
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
# load helpers
source('../../results/helpers.R')
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value))
str(t$Value)
mean(t$Value)
# load helpers
source('../../results/helpers.R')
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
theme_set(theme_bw())
# load libraries
library(plyr)
library(lme4)
library(lmerTest)
library(ggplot2)
library(tidyverse)
library(broom)
library(emmeans)
library(ordinal)
library(brms)
# load helpers
source('../../results/helpers.R')
# read data from exp 3 in Mandelkern et al 2020
results <- read.csv("../data/IncrSymAccResults.txt", comment.char="#", header=F)
# load data
results <- read.csv("../data/resultsExp1.csv")
# filter to data of interest (SSimplePs = support simple ps, EISimplePS = explicit ignorance simple ps)
d = results %>%
filter(Condition == "SSimplePs" | Condition == "EISimplePs") %>%
droplevels()
table(d$Condition)
# read data from exp 3 in Mandelkern et al 2020
results <- read.csv("../data/IncrSymAccResults.txt", comment.char="#", header=F)
# load data
results <- read.csv("../data/resultsExp1.csv")
# filter to data of interest (SSimplePs = support simple ps, EISimplePS = explicit ignorance simple ps)
d = results %>%
filter(Condition == "SSimplePs" | Condition == "EISimplePs") %>%
droplevels()
table(d$Condition)
view(results)
# load data
results <- read.csv("../data/resultsExp1.csv")
view(results)
table(results$Condition)
# load data
results <- read.csv("../data/resultsExp1.csv")
view(results)
table(results$Condition)
results <- read.csv("https://159d3d98-11fc-4642-8e29-43c994fa07d0.usrfiles.com/ugd/159d3d_ab22ce000af244c4a2410dc21d6c6a68.csv")
table(results$Condition)
view(results)
library(plyr)
library(lme4)
library(lmerTest)
library(ggplot2)
library(tidyverse)
library(broom)
library(emmeans)
library(ordinal)
library(brms)
results <- read.csv("https://159d3d98-11fc-4642-8e29-43c994fa07d0.usrfiles.com/ugd/159d3d_ab22ce000af244c4a2410dc21d6c6a68.csv")
First overview plots:
```{r}
results$Condition <- (as.factor(as.character(results$Condition)))
levels(results$Condition) <- c("NoPsFirst", "NoPsSecond", "PsFirst", "PsSecond", "EISimplePs", "SSimplePs")
results <- as_tibble(results)
results <- results %>%
mutate(Condition = fct_relevel(Condition,
c("PsFirst", "PsSecond", "NoPsFirst", "NoPsSecond", "EISimplePs", "SSimplePs")))
resultsPlot <- results %>%
group_by(Condition) %>%
dplyr::summarize(n = n(), MeanValue = mean(Value), sd = sd(Value))%>%
mutate( se=sd/sqrt(n))  %>%
mutate( ci=se * qt((1-0.05)/2 + .5, n-1))
colours <- c("#727272", "#f1595f", "#79c36a", "#599ad3", "#f9a65a" , "#9e66ab")
ggplot(resultsPlot, aes(x = Condition, y = MeanValue, fill=Condition))+
geom_bar(stat = "identity") +
ylim("1", "2", "3", "4", "5", "6", "7")+
geom_errorbar(aes(ymin=MeanValue-se, ymax=MeanValue+se), width=.1) +
scale_fill_manual(values=colours)+
theme(axis.text.x = element_text(angle = 45)) +
theme_classic() +
labs(title = "Mean rating per condition",
y = "Mean rating",
x = "Condition")
results <- read.csv("https://159d3d98-11fc-4642-8e29-43c994fa07d0.usrfiles.com/ugd/159d3d_ab22ce000af244c4a2410dc21d6c6a68.csv")
view(results)
table(results$Condition)
# load helpers
source('../../results/helpers.R')
# load data
results <- read.csv("../data/resultsExp1.csv")
view(results)
table(results$Condition)
# filter to data of interest (Support = support simple ps, SimplePs = explicit ignorance simple ps)
d = results %>%
filter(Condition == "Support" | Condition == "SimplePs") %>%
droplevels()
table(d$Condition)
# target data: explicit ignorance context
t = d %>%
filter(Condition == "SimplePS")
nrow(t)
#view(t)
table(t$Trigger)
#view(t)
table(t$Trigger)
# target data: explicit ignorance context
t = d %>%
filter(Condition == "SimplePS")
nrow(t)
# target data: explicit ignorance context
t = d %>%
filter(Condition == "SimplePs")
nrow(t)
#view(t)
table(t$Trigger)
str(t)
table(t$Value) #1-7
str(t$Value)
mean(t$Value)
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
nat.meansEIC
levels(nat.meansEIC$expression)
#view(t)
table(t$Trigger)
#  again    aware continue find out    happy     stop
table(t$Value) #1-7
str(t$Value)
mean(t$Value)
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value))
# target data: explicit ignorance context
t = d %>%
filter(Condition == "SimplePs")
nrow(t)
#view(t)
table(t$Trigger)
#  again    aware continue find out    happy     stop
table(t$Value) #1-7
str(t$Value)
mean(t$Value)
t$Value <- as.numeric(t$Value)
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
str(t$Value)
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
theme_set(theme_bw())
# load helpers
source('../../results/helpers.R')
# load data
results <- read.csv("../data/resultsExp1.csv")
view(results)
table(results$Condition)
# filter to data of interest (Support = support simple ps, SimplePs = explicit ignorance simple ps)
d = results %>%
filter(Condition == "Support" | Condition == "SimplePs") %>%
droplevels()
table(d$Condition)
# target data: explicit ignorance context
t = d %>%
filter(Condition == "SimplePs")
nrow(t)
#view(t)
table(t$Trigger)
#  again    aware continue find out    happy     stop
table(t$Value) #1-7
str(t$Value)
mean(t$Value)
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value))
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
## for bootstrapping 95% confidence intervals
library(bootstrap)
## for bootstrapping 95% confidence intervals
library(bootstrap)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
# load data
results <- read.csv("../data/resultsExp1.csv")
#view(results)
table(results$Condition)
# filter to data of interest (Support = support simple ps, SimplePs = explicit ignorance simple ps)
d = results %>%
filter(Condition == "Support" | Condition == "SimplePs") %>%
droplevels()
table(d$Condition)
# target data: explicit ignorance context
t = d %>%
filter(Condition == "SimplePs")
nrow(t)
#view(t)
table(t$Trigger)
#  again    aware continue find out    happy     stop
table(t$Value) #1-7
str(t$Value)
mean(t$Value)
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
t$Value <- as.numeric(t$Value)
t$Value <- as.numeric(t$Value)
t = d %>%
filter(Condition == "SimplePs")
nrow(t)
#view(t)
table(t$Trigger)
#  again    aware continue find out    happy     stop
table(t$Value) #1-7
str(t$Value)
mean(t$Value)
t$Value <- as.numeric(t$Value)
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(Trigger) %>%
summarize(Mean = mean(Value), CILow = ci.low(Value), CIHigh = ci.high(Value)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(Trigger),Mean))
# load packages
library(tidyverse)
library(reshape2)
library(lme4)
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
theme_set(theme_bw())
# load helpers
source('../../results/helpers.R')
# read data from exp 3 in Mandelkern et al 2020
results <- read.csv("../data/IncrSymAccResults.txt", comment.char="#", header=F)
# assign column names
names(results) <- c("ReceptionTime", "IP", "Controller", "It", "Elements", "Type", "Group", "Question", "Answer", "Time")
# subset the data into meta (?, something about experiment coding?) and results
meta <- subset(results, Controller!="DynamicQuestion")
results <- subset(results, Controller=="DynamicQuestion")
# now the 'Question' column is split into separate columns based on +
results <- cbind(results, colsplit(results$Question, "[+]", c("item","group","condition","context", "trigger", "sentence", "inference")))
# Creating subject IDs by combining IP and time
results$subject <- paste(results$IP, results$ReceptionTime)
length(unique(results$subject))
# remove practice trials
practice <- subset(results, Type=="practice")
results <- subset(results, Type!="practice")
# make ordinal Answers numeric
results$Answer <- as.numeric(as.character(results$Answer))
table(results$Answer) # answers between 0 and 6 (ordinal)
# context is Explicit Ignorance or Support
table(results$context)
# "trigger" codes the expression (- means no trigger)
table(results$trigger)
# select relevant columns
results = results %>%
select(c("Answer","item","condition","context","trigger","sentence","inference","subject"))
# code whether something was a ps trigger or not
results$ps <- "not presupposition"
results$ps[results$trigger=="aware"|results$trigger=="happy"|results$trigger=="stop"|results$trigger=="continue"] <- "presupposition"
table(results$trigger, results$ps)
# item coding: items with numbers above 40 don't have "If..."-sentence (filler)
results$item <- as.numeric(results$item)
# remove such rows from the dataset
results <- results %>%
filter(item <= 40)
# remove the rows without a trigger
results <- results %>%
filter(trigger != "-")
table(results$trigger)
# target data: explicit ignorance context
t = results %>%
filter(context == "ExplicitIgnoranceP")
nrow(t)
table(t$trigger)
str(t)
table(t$Answer) #0-6
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(trigger) %>%
summarize(Mean = mean(Answer), CILow = ci.low(Answer), CIHigh = ci.high(Answer)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(trigger),Mean))
nat.meansEIC
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(trigger) %>%
summarize(Mean = mean(Answer), CILow = ci.low(Answer), CIHigh = ci.high(Answer)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(trigger),Mean))
t = results %>%
filter(context == "ExplicitIgnoranceP")
# this R script is a modification of the R script downloaded from the OSF repo provided in
# Mandelkern et al 2020 (https://osf.io/jwcvr)
# it calls the data from Exp 3
# load packages
library(tidyverse)
library(reshape2)
library(lme4)
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
theme_set(theme_bw())
# load helpers
source('../../results/helpers.R')
# read data from exp 3 in Mandelkern et al 2020
results <- read.csv("../data/IncrSymAccResults.txt", comment.char="#", header=F)
#view(results)
# assign column names
names(results) <- c("ReceptionTime", "IP", "Controller", "It", "Elements", "Type", "Group", "Question", "Answer", "Time")
#view(results)
# subset the data into meta (?, something about experiment coding?) and results
meta <- subset(results, Controller!="DynamicQuestion")
results <- subset(results, Controller=="DynamicQuestion")
# '+' was used as a separating character in 'Question', so the 'p+' in 'SupportP+' in 'Question' was replaced by "p+" (not sure what this is about)
#table(results$Question)
#results$Question <- sub("[+][+]", "p+", results$Question)
# now the 'Question' column is split into separate columns based on +
results <- cbind(results, colsplit(results$Question, "[+]", c("item","group","condition","context", "trigger", "sentence", "inference")))
# Creating subject IDs by combining IP and time
results$subject <- paste(results$IP, results$ReceptionTime)
length(unique(results$subject))
#[1] 126
# remove practice trials
practice <- subset(results, Type=="practice")
results <- subset(results, Type!="practice")
# make ordinal Answers numeric
results$Answer <- as.numeric(as.character(results$Answer))
table(results$Answer) # answers between 0 and 6 (ordinal)
# context is Explicit Ignorance or Support
table(results$context)
# "trigger" codes the expression (- means no trigger)
table(results$trigger)
# select relevant columns
results = results %>%
select(c("Answer","item","condition","context","trigger","sentence","inference","subject"))
#view(results)
# Answer: rating given by the participant
# item: item number
# condition: Acceptable (filler?), P (ps but no conjunction), TrF (trigger first), TrL (trigger last), Unacceptable (filler?)
# context: ExplicitIgnoranceP, SupportP (whether the context is an EI context or a context that satisfies the ps)
# trigger: aware, continue, enjoy, frown on, happy, hoping, stop, sure and --
# sentence: the sentence that participants read
# inference: the sentence that represents the inference of interest in the sentence that participants read
# subject: participant ID
# code whether something was a ps trigger or not
results$ps <- "not presupposition"
results$ps[results$trigger=="aware"|results$trigger=="happy"|results$trigger=="stop"|results$trigger=="continue"] <- "presupposition"
table(results$trigger, results$ps)
# item coding: items with numbers above 40 don't have "If..."-sentence (filler)
results$item <- as.numeric(results$item)
# remove such rows from the dataset
results <- results %>%
filter(item <= 40)
# remove the rows without a trigger
results <- results %>%
filter(trigger != "-")
table(results$trigger)
# target data: explicit ignorance context
t = results %>%
filter(context == "ExplicitIgnoranceP")
nrow(t)
table(t$trigger)
str(t)
table(t$Answer) #0-6
# calculate mean naturalness rating by expression in explicit ignorance context
nat.meansEIC = t %>%
group_by(trigger) %>%
summarize(Mean = mean(Answer), CILow = ci.low(Answer), CIHigh = ci.high(Answer)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(trigger),Mean))
detach("package:base", unload = TRUE)
detach("package:bootstrap", unload = TRUE)
detach("package:brms", unload = TRUE)
detach("package:broom", unload = TRUE)
detach("package:datasets", unload = TRUE)
detach("package:dplyr", unload = TRUE)
detach("package:emmeans", unload = TRUE)
detach("package:forcats", unload = TRUE)
detach("package:ggh4x", unload = TRUE)
detach("package:ggplot2", unload = TRUE)
detach("package:graphics", unload = TRUE)
detach("package:grDevices", unload = TRUE)
detach("package:jsonlite", unload = TRUE)
detach("package:lme4", unload = TRUE)
detach("package:lmerTest", unload = TRUE)
detach("package:lubridate", unload = TRUE)
detach("package:Matrix", unload = TRUE)
detach("package:methods", unload = TRUE)
detach("package:plyr", unload = TRUE)
detach("package:purrr", unload = TRUE)
detach("package:Rcpp", unload = TRUE)
detach("package:readr", unload = TRUE)
detach("package:reshape2", unload = TRUE)
detach("package:rwebppl", unload = TRUE)
detach("package:stats", unload = TRUE)
detach("package:stringr", unload = TRUE)
detach("package:tibble", unload = TRUE)
detach("package:tidyr", unload = TRUE)
detach("package:tidyverse", unload = TRUE)
detach("package:utils", unload = TRUE)
# load packages
library(tidyverse)
# load packages
library(tidyverse)
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
theme_set(theme_bw())
# load helpers
source('../../results/helpers.R')
